---
title: 'STAT 224 Autumn 2022 HW7'
author: "Matthew Zhao"
fontsize: 12pt
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
header-includes: \usepackage{pdfpages}
geometry: margin=0.5in
fig_crop: no
---

```{r echo=F, include = FALSE}
library(knitr)
library(ggplot2)
knitr::opts_chunk$set(fig.width=4, fig.height=3, message=F, warning=F, collapse=TRUE)
options(width=70, digits=5, scipen=8)
options(show.signif.stars = FALSE) # Show no stars for significance tests
```

# Question 1

http://www.stat.uchicago.edu/~yibi/s224/data/P229-30.txt

```{r}
stock = read.table("http://www.stat.uchicago.edu/~yibi/s224/data/P229-30.txt", header=T)
```

## Q1a --- 4 points

```{r}
stock1 = lm(DJIA ~ Day, data=stock)
```

```{r}
x = stock$Day
y = stock$DJIA
n = length(y)
n.iter = 15
rho.iter = vector("numeric", n.iter)
b0.iter = vector("numeric", n.iter)
b1.iter = vector("numeric", n.iter)
fit1 = lm(y ~ x)
res = fit1$res
rho.iter[1] = sum(res[1:(n-1)]*res[2:n]) / sum(res^2)
for(i in 2:n.iter){
  rho.iter[i] = sum(res[1:(n-1)]*res[2:n]) / sum(res^2)
  ystar = y[2:n] - rho.iter[i]*y[1:(n-1)]
  xstar = x[2:n] - rho.iter[i]*x[1:(n-1)]
  fit2 = lm(ystar ~ xstar)$coef
  b0.iter[i] = fit2[1]/(1-rho.iter[i])
  b1.iter[i] = fit2[2]
  res = y - b0.iter[i] - b1.iter[i]*x
}
data.frame(rho.iter,b0.iter,b1.iter)
```

$\beta_0 = 5209.5$, $\beta_1 = 4.2653$, $\rho = 0.97166$

## Q1b --- 2 points

```{r}
x = stock$Day
y = stock$DJIA
n = length(y)
rho_hat = 0.97166
x_star = x[2:n] - rho_hat*x[1:(n-1)]
y_star = y[2:n] - rho_hat*y[1:(n-1)]

ggplot(mapping = aes(x=x_star,y=y_star)) +
  geom_point() +
  labs(x='x star',y='y star', title = 'Checking Model Assumptions')
```

We do not see any violation of assumptions.

## Q1c --- 6 points

```{r, warning=FALSE}
lm_star = lm(y_star ~ x_star)
ggplot(mapping=aes(x=x_star,y=lm_star$residuals)) + 
  geom_line() + geom_point()+
  labs(x='Time (day)','Raw Residuals') + 
  geom_hline(yintercept = 0)
library(tseries)
library(car)
runs.test(factor(lm_star$residuals > 0))
durbinWatsonTest(lm_star)
acf(lm_star$residuals)
```

## Q1d --- 3 points

We should use lm(ystar ~ xstar) since this model does not violate any SLR assumptions compared to the lm(DJIA ~ Day) model as we saw in HW 6. 

```{r}
confint(lm_star)
```

95% CI for $\beta_1$: (1.8595,6.6711)

# Question 2

http://www.stat.uchicago.edu/~yibi/s224/data/globalwarm.txt

```{r, message=FALSE, fig.width=6, fig.height=2, out.width='100%'}
gw = read.table("http://www.stat.uchicago.edu/~yibi/s224/data/globalwarm.txt", header=T)
```

```{r}
gwlm1 = lm(Temperature ~ Year + I(Year^2), data=gw)
```

## Q2a --- 3 points

```{r, fig.width=7, fig.height=2}
lag.plot(gwlm1$res, lag=4, layout=c(1,4))
```

```{r}
acf(gwlm1$res)
```

We conclude that there is autocorrelation between the residuals as seen by the lag plots for lag 1 to 4 and in the acf plot from 1-10.

## Q2b --- 4 points

```{r}
x = gw$Year
v = (gw$Year)^2
y = gw$Temperature
n = length(y)
n.iter = 15
rho.iter = vector("numeric", n.iter)
b0.iter = vector("numeric", n.iter)
b1.iter = vector("numeric", n.iter)
b2.iter = vector("numeric", n.iter)
fit1 = lm(y ~ x + v)
res = fit1$res
rho.iter[1] = sum(res[1:(n-1)]*res[2:n]) / sum(res^2)
for(i in 2:n.iter){
  rho.iter[i] = sum(res[1:(n-1)]*res[2:n]) / sum(res^2)
  ystar = y[2:n] - rho.iter[i]*y[1:(n-1)]
  xstar = x[2:n] - rho.iter[i]*x[1:(n-1)]
  vstar = v[2:n] - rho.iter[i]*v[1:(n-1)]
  fit2 = lm(ystar ~ xstar + vstar)$coef
  b0.iter[i] = fit2[1]/(1-rho.iter[i])
  b1.iter[i] = fit2[2]
  b2.iter[i] = fit2[3]
  res = y - b0.iter[i] - b1.iter[i]*x - b2.iter[i]*v
}
data.frame(rho.iter,b0.iter,b1.iter,b2.iter)
```

$\beta_0 = 208.96$, $\beta_1 = -0.22129$, $\beta_2 = 0.000058498$, $\rho = 0.59249$

## Q2c --- 6 points

```{r, warning=FALSE}
x_star = x[2:n] - rho_hat*x[1:(n-1)]
v_star = (x[2:n])^2 - rho_hat*(x[1:(n-1)])^2
y_star = y[2:n] - rho_hat*y[1:(n-1)]

lm_star = lm(y_star ~ x_star + v_star)
res = lm_star$residuals
ggplot(mapping=aes(x=x_star,y=res)) + 
  geom_line() + geom_point()+
  labs(x='Year',y='Raw Residuals',title = 'time plot') + 
  geom_hline(yintercept = 0)
runs.test(factor(res > 0))
n = length(y_star)
for (k in c(1:4)) {
  print(ggplot(mapping=aes(x=res[(k+1):n],y=res[1:(n-k)])) + 
    geom_line() + geom_point() +
    labs(title = paste('lag',k)) + 
    geom_smooth(method='lm'))
}
acf(res)
```

We conclude from these tests that there is no evidence of autocorrelation.

# Question 3

http://www.stat.uchicago.edu/~yibi/s224/data/skincancer.txt


```{r}
skincancer = read.table("http://www.stat.uchicago.edu/~yibi/s224/data/skincancer.txt", header=T)
```

## Q3a --- 6 points

```{r}
model2 = lm(sqrt(Melanoma) ~ Year, data=skincancer)
```

```{r, warning=FALSE}
x=skincancer$Year
y=sqrt(skincancer$Melanoma)
res = model2$residuals
ggplot(mapping=aes(x=skincancer$Year,y=res)) + 
  geom_line() + geom_point()+
  labs(x='Year',y='Raw Residuals',title = 'time plot') + 
  geom_hline(yintercept = 0)
runs.test(factor(res > 0))
n = length(y)

for (k in c(1:8)) {
  print(ggplot(mapping=aes(x=res[(k+1):n],y=res[1:(n-k)])) + 
    geom_line() + geom_point() +
    labs(title = paste('lag',k)) + 
    geom_smooth(method='lm'))
}
acf(res)
```

The time plot shows some evidence of runs, while the runs test fails to reject at the 5% significance level with p=0.14, indicating some potential autocorrelation. The lag-k plots appear to be showing some evidence of autocorrelation while the acf plot shows weak evidence for autocorrelation.

## Q3b --- 6 points


$$
\sqrt{\text{Melanoma}_t}=\beta_0+\beta_1\text{Year}_t+
\beta_2\sqrt{\text{Sunspot}_{t}}+
\beta_3\sqrt{\text{Sunspot}_{t-1}}+
\beta_4\sqrt{\text{Sunspot}_{t-2}}+
\varepsilon_t 
$$
```{r}
model3 = lm(sqrt(Melanoma[3:37]) ~ Year[3:37] + sqrt(Sunspot[3:37]) +
              sqrt(Sunspot[2:36]) + sqrt(Sunspot[1:35]), data=skincancer)
```
```{r, warning=FALSE}
x=skincancer$Year[3:37]
res = model3$residuals
ggplot(mapping=aes(x=x,y=res)) + 
  geom_line() + geom_point()+
  labs(x='Year',y='Raw Residuals',title = 'time plot') + 
  geom_hline(yintercept = 0)
runs.test(factor(res > 0))
n = length(x)

for (k in c(1:8)) {
  print(ggplot(mapping=aes(x=res[(k+1):n],y=res[1:(n-k)])) + 
    geom_line() + geom_point() +
    labs(title = paste('lag',k)) + 
    geom_smooth(method='lm'))
}
acf(res)
```

Now the tests reveal virtually no evidence of autocorrelation.

# Question 4

http://www.stat.uchicago.edu/~yibi/s224/data/food.txt

```{r}
food = read.table("http://www.stat.uchicago.edu/~yibi/s224/data/food.txt", h = T)
```

## Q4a --- 3 points

```{r}
lmfood = lm(log(V)~log(K)+log(L)+YEAR, data=food)
```


```{r, fig.width=4, fig.height=4}
panel.cor <- function(x, y, digits = 3, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    text(0.5, 0.5, round(cor(x,y),digits))
}
pairs(log(V)~log(K)+log(L)+YEAR, data=food,
      gap=0,oma=c(2,2,2,2), lower.panel = panel.cor)
vif(lmfood)
```

From the pairwise scatterplots and the VIFs we see that labor and year are collinear (VIF > 10 and nearly -1 correlation). 

## Q4b --- 3 points

```{r}
summary(lm(log(V)~log(K)+log(L)+YEAR, data=food))$coef
summary(lm(log(V)~log(K)+log(L), data=food))$coef
summary(lm(log(V)~log(K)+YEAR, data=food))$coef
```

YEAR becomes significant at the 5% level when L is removed from the model while L becomes significant when YEAR is removed from the model. I do not believe there was technological development in the food sector since its coefficient is not significant in any model. We can conclude that increasing labor input would lead to decrease in the output based on the second model.

# Question 5

http://www.stat.uchicago.edu/~yibi/s224/data/fevdata.txt

```{r}
fevdata = read.table("http://www.stat.uchicago.edu/~yibi/s224/data/fevdata.txt", header = TRUE)
fevdata$sex = factor(fevdata$sex, labels=c("Female","Male"))
fevdata$smoke = factor(fevdata$smoke, labels=c("Nonsmoker","Smoker"))
```

## Q5a --- 2 points

```{r}
m.nonsmokers = subset(fevdata, sex=="Male" & smoke=="Nonsmoker")
mod1 = lm(log(fev) ~ ht, data=m.nonsmokers)
mod2 = lm(log(fev) ~ ht + I(ht^2), data=m.nonsmokers)
summary(mod1)$coef
summary(mod2)$coef
```
```{r}
vif(mod2)
ggplot(data = m.nonsmokers, aes(x=ht,y=ht^2)) +
  geom_point() + 
  labs(x='Height',y='Height^2') + 
  geom_smooth(method='lm')
```

This happens because ht and ht^2 are collinear (VIF >>> 10 and plot shows they are nearly exactly linearly related).

## Q5b --- 2 points


```{r, eval=FALSE}
mod3 = lm(log(fev) ~ ht + I((ht-60)^2), data=m.nonsmokers)
summary(mod3)$coef
```
```{r}
vif(mod3)
ggplot(data = m.nonsmokers, aes(x=ht,y=(ht-60)^2)) +
  geom_point() + 
  labs(x='Height',y='Height^2') + 
  geom_smooth(method='lm')
```

Now there is no collinearity between the two as evidenced by a small VIF and the graph shown.
